{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1039d805",
   "metadata": {},
   "source": [
    "<h3>Step-1 Trying to load all 3 types of PDF </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d62ba69",
   "metadata": {},
   "source": [
    "<h4>Loading Text BAsed pdf</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "Loaded the text document : 420\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "load_dotenv()\n",
    "TEXT_PDF_PATH=os.getenv(\"TEXT_PDF_PATH\")\n",
    "\n",
    "#loading the document\n",
    "text_loader=PyMuPDFLoader(TEXT_PDF_PATH)\n",
    "text_docs=text_loader.load()\n",
    "print(\"Success\")\n",
    "print(f\"Loaded the text document : {len(text_docs)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66bb6f2",
   "metadata": {},
   "source": [
    "Using PyMuPDF Loader because as per documentation\n",
    "\n",
    "Document Lazy Loading   \t   \n",
    "\n",
    "Native Async Support \t   \n",
    "\n",
    "Extract Images \t        \n",
    "\n",
    "Extract Tables\n",
    "\n",
    "https://python.langchain.com/docs/integrations/document_loaders/pymupdf/#setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea71cd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg eBook of A Journey to the Centre of the Earth\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at www.gutenberg.org. If you are not located in the United States,\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this eBook.\n",
      "Title: A Journey to the Centre of the Earth\n",
      "Author: Jules Verne\n",
      "Release date: July 18, 2006 [eBook #18857]\n",
      "                Most recently updated: December 27, 2012\n",
      "Language: English\n",
      "Original publication: Griffith and Farran,, 1871\n",
      "Credits: Produced by Norm Wolcott\n",
      "*** START OF THE PROJECT GUTENBERG EBOOK A JOURNEY TO THE CENTRE OF THE\n",
      "EARTH ***\n"
     ]
    }
   ],
   "source": [
    "#checking the content\n",
    "print(text_docs[0].page_content[:1000]) #fetching first 1000 characters from page 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcee0bf",
   "metadata": {},
   "source": [
    "# loading for table based document heavy ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fbc5eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "load_dotenv()\n",
    "TABLE_PDF_PATH=os.getenv(\"TABLE_PDF_PATH\")\n",
    "table_docs=PDFPlumberLoader(TABLE_PDF_PATH)\n",
    "table_loader=table_docs.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7a22e7",
   "metadata": {},
   "source": [
    "| Loader             | Best For                             | Can Extract Tables? | Notes                                            |\n",
    "| ------------------ | ------------------------------------ | ------------------- | ------------------------------------------------ |\n",
    "| `PyMuPDFLoader`    | Normal text-based PDFs (like novels) | ‚ùå Not reliably      | Gives free-form text only, loses table structure |\n",
    "| `PDFPlumberLoader` | Tabular/financial/data-heavy PDFs    | ‚úÖ Yes               | Designed for extracting structured tables        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5567184a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country NCountry CSeries NamSeries Cod2015 [YR22016 [YR22017 [YR22018 [YR22019 [YR22020 [YR22021 [YR22022 [YR22023 [YR22024 [YR2\n",
      "Australia AUS Access to EG.CFT.AC 100 100 100 100 100 100 100 100 .. ..\n",
      "Australia AUS Access to EG.CFT.AC 100 100 100 100 100 100 100 100 .. ..\n",
      "Australia AUS Access to EG.CFT.AC 100 100 100 100 100 100 100 100 .. ..\n",
      "Australia AUS Access to EG.ELC.AC 100 100 100 100 100 100 100 100 100 ..\n",
      "Australia AUS Access to EG.ELC.AC 100 100 100 100 100 100 100 100 100 ..\n",
      "Australia AUS Access to EG.ELC.AC 100 100 100 100 100 100 100 100 100 ..\n",
      "Australia AUS Account oFX.OWN.T.. .. 99.52 .. .. .. 99.32 .. .. ..\n",
      "Australia AUS Account oFX.OWN.T.. .. 99.2 .. .. .. 100 .. .. ..\n",
      "Australia AUS Account oFX.OWN.T.. .. 99.85 .. .. .. 98.59 .. .. ..\n",
      "Australia AUS Account oFX.OWN.T.. .. 99.64 .. .. .. 99.18 .. .. ..\n",
      "Australia AUS Account oFX.OWN.T.. .. 99.29 .. .. .. 98.3 .. .. ..\n",
      "Australia AUS Account oFX.OWN.T.. .. 100 .. .. .. 86.48 .. .. ..\n",
      "Australia AUS Account oFX.OWN.T.. .. 99.\n"
     ]
    }
   ],
   "source": [
    "print(table_loader[0].page_content[:1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4ee419",
   "metadata": {},
   "source": [
    "# loading image based pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d608c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document('D:\\AGI Projects\\MultiPDF RAG Pipeline\\Dataset\\100 SQL COMMANDS .pdf')\n",
      "Loaded 9 pages with image-based text\n",
      "--------------------------------------------------\n",
      "Sample content:\n",
      "\n",
      "@, Vikram\n",
      "# ~ ecode. learning\n",
      "\n",
      "100 SQL\n",
      "Commands\n",
      "\n",
      "Metadata: {'page': 1, 'source': 'image'}\n"
     ]
    }
   ],
   "source": [
    "# loaders/load_image_pdf.py\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image # to extract a single image from pdf\n",
    "from pytesseract import image_to_string  #to extract text and return string\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Load env variables\n",
    "load_dotenv()\n",
    "IMAGE_PDF_PATH = os.getenv(\"IMAGE_PDF_PATH\")\n",
    "\n",
    "def read_image_pdf(path):\n",
    "    doc = fitz.open(path)\n",
    "    #doc is now a list object where each item is page of pdf\n",
    "    print(doc)\n",
    "    image_docs = []\n",
    "    # Empty list to store all the extracted pages as LangChain Document objects.\n",
    "\n",
    "    for page in doc:\n",
    "        # Try text extraction\n",
    "        text = page.get_text().strip()\n",
    "        if not text:\n",
    "            # print(\"No text found\")- This if looop was entered 9 times\n",
    "            # Convert page to image for OCR\n",
    "            pix = page.get_pixmap()\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            text = image_to_string(img)\n",
    "\n",
    "        if text.strip():\n",
    "            image_docs.append(Document(\n",
    "                page_content=text.strip(),\n",
    "                metadata={\"page\": page.number + 1, \"source\": \"image\"}\n",
    "            ))\n",
    "\n",
    "    return image_docs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    docs = read_image_pdf(IMAGE_PDF_PATH)\n",
    "    print(f\"Loaded {len(docs)} pages with image-based text\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Sample content:\\n\")\n",
    "    print(docs[0].page_content[:500])\n",
    "    print(\"\\nMetadata:\", docs[0].metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef27d7e",
   "metadata": {},
   "source": [
    "Explanation of the above code\n",
    "\n",
    "<h4>import fitz</h4> \n",
    "\n",
    "It's just a name to call PyMuPDF library for reading and working with PDF files\n",
    "\n",
    "Can:\n",
    "\n",
    "Extract text (page.get_text())\n",
    "\n",
    "Convert pages to images (page.get_pixmap())\n",
    "\n",
    "Read metadata, bookmarks, etc.\n",
    "\n",
    "<h4>from PIL import Image</h4> \n",
    "\n",
    "Imports Image from the Pillow library (Python Imaging Library).\n",
    "\n",
    "Used here to handle images converted from PDF pages.\n",
    "\n",
    "Converts pixmap (from PyMuPDF) into a format that OCR tools can understand.\n",
    "\n",
    "<h4>from pytesseract import image_to_string</h4> \n",
    "\n",
    "From the pytesseract package (Python wrapper for Google‚Äôs Tesseract OCR engine).\n",
    "\n",
    "image_to_string() takes an image and returns the extracted text.\n",
    "\n",
    "You use it when a PDF contains text inside images (non-selectable).\n",
    "\n",
    "<h4>from langchain_core.documents import Document</h4>\n",
    "\n",
    "Part of LangChain‚Äôs core data structure.\n",
    "\n",
    "Document is a wrapper that holds:\n",
    "\n",
    "page_content ‚Üí the actual text\n",
    "\n",
    "metadata ‚Üí source, page number, type, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4778fc35",
   "metadata": {},
   "source": [
    "üîß def read_image_pdf(path):\n",
    "Defines a function that takes the path to an image-based PDF and returns a list of LangChain Document objects, each containing extracted text + metadata.\n",
    "\n",
    "üìÑ doc = fitz.open(path)\n",
    "Opens the PDF using PyMuPDF.\n",
    "\n",
    "doc becomes a list-like object where each item is a page of the PDF.\n",
    "\n",
    "üì¶ image_docs = []\n",
    "Empty list to store all the extracted pages as LangChain Document objects.\n",
    "\n",
    "üîÅ for page in doc:\n",
    "Iterates through each page of the PDF file.\n",
    "\n",
    "üß™ text = page.get_text().strip()\n",
    "Tries to extract any embedded text from the page directly (like in normal PDFs).\n",
    "\n",
    ".strip() removes extra whitespace.\n",
    "\n",
    "If the PDF has scanned images only, this will likely return an empty string.\n",
    "\n",
    "‚ùó if not text:\n",
    "If get_text() didn‚Äôt return anything (i.e., the page has no selectable text):\n",
    "\n",
    "python\n",
    "Copy code\n",
    "print(\"No text found\")\n",
    "Gives you feedback during debugging.\n",
    "\n",
    "üñºÔ∏è pix = page.get_pixmap()\n",
    "Converts the entire PDF page into a raster image (pixel map).\n",
    "\n",
    "You need this for OCR, because image_to_string() expects an image.\n",
    "\n",
    "üß† img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "Converts the pixmap to a Pillow Image object, so it can be passed to Tesseract.\n",
    "\n",
    "üîç text = image_to_string(img)\n",
    "Performs OCR (Optical Character Recognition) on the image of the page.\n",
    "\n",
    "Converts image content (like SQL diagrams, screenshots, or scanned docs) into raw text.\n",
    "\n",
    "‚úÖ if text.strip():\n",
    "If OCR extracted any non-empty text, then proceed to save it.\n",
    "\n",
    "üì¶ image_docs.append(Document(...))\n",
    "Wraps the extracted text and some helpful metadata into a LangChain Document object.\n",
    "\n",
    "Metadata includes:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "{\n",
    "    \"page\": page.number + 1,\n",
    "    \"source\": \"image\"\n",
    "}\n",
    "This tells you:\n",
    "\n",
    "Which page the text came from\n",
    "\n",
    "That it came from the image-based PDF\n",
    "\n",
    "üîö return image_docs\n",
    "Returns the list of extracted pages, each as a Document object, ready to be chunked, embedded, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b18a5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
